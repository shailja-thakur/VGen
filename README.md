# Benchmarking-LLM-Verilog

This is our work on benchmarking Large Language Models (LLM) for automatically generating Verilog.
The repository comprises of the following:
1. Scripts for Verilog pre-processing from GitHub 
2. Script for fine-tuning and evaluation of LLMs 
3. Preparing the code corpus for fine-tuning purpose
4. Sctipts used in the evaluation pipeline (preparing hardware design tasks, create test-benches, compile, test on test-benches, gather results, generate a comprehensive report)
5. Inference (Jupyter Notebook/Fauxpilot with fine-tuned model)
6. Scripts for result visualization

The checkpoints of the fine-tuned versions of LLMs for Verilog are available on [ Huggingface ](https://huggingface.co/shailja)

More details coming soo ...


