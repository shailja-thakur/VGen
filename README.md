# Benchmarking-LLM-Verilog

This is our work on benchmarking Large Language Models (LLM) for automatically generating Verilog.
The repository comprises of the following:
1. Pre-processing scripts
2. Fine-tuning scripts
3. Sctipts used in the evaluation pipeline (Design tasks, preparing test-benches, compilation and test scripts, results accumulation, comprehensive report)
4. Inference (Jupyter Notebook/Fauxpilot with fine-tuned model)
5. Scripts for result visualization

The checkpoints for the fine-tuned LLMs for Verilog are available on [ Huggingface ](https://huggingface.co/shailja)

More details coming soo ...


