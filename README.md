# Benchmarking-LLM-Verilog

This is our work on benchmarking Large Language Models (LLM) for automatically generating Verilog.
The repository comprises of the following:
1. Scripts for filtering the code and preparing the dataset for fine-tuning purpose
2. Sctipts used in the evaluation pipeline (Preparing hardware design tasks, Program synthesis, create test-benches, compile, generate results)
4. Set of hardware design problems for evaluation

The checkpoints for the fine-tuned versions of LLMs are available on [ Huggingface ](https://huggingface.co/shailja)

More details coming soo ...


